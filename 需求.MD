# binlogx 开发提示词

## 一、项目定位
**binlogx** 是基于 Go 1.25 的高性能 binlog 处理工具，支持  
离线文件 / 在线数据库 两种数据源，对 MySQL binlog 进行  
统计｜解析｜SQL 生成｜回滚 SQL｜多格式导出，并具备  
**分库表正则路由 + 列名缓存 + 生产者-消费者并发 + 慢监控 + 大事件预警**。

---

## 二、命令总览
| 命令 | 描述 |
|------|------|
| `stat` | 总事件数、库/表/Action 分布 |
| `parse` | 交互式分页查看事件详情 |
| `sql` | 输出可执行 SQL |
| `rollback-sql` | 生成反向回滚 SQL |
| `export` | 导出为 csv、sqlite、h2、hive、es |
| `version` | 版本号、构建时间、Git 分支、CommitID |

---

## 三、全局参数（所有命令共用）
| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `--source` | string | ① | 离线 binlog 文件路径 |
| `--db-connection` | string | ① | 在线 DSN `user:pass@tcp(host:port)/dbname?charset=utf8mb4` |
| `--start-time` | string | N | 开始时间 `YYYY-MM-DD HH:MM:SS` |
| `--end-time` | string | N | 结束时间 `YYYY-MM-DD HH:MM:SS` |
| `--action` | []string | N | 操作类型过滤 |
| `--slow-threshold` | duration | N | 慢方法阈值，默认 50ms |
| `--event-size-threshold` | int | N | 事件大小阈值（字节），默认 1024 |
| `--schema-table-regex` | []string | N | schema.table 正则表达式，例 `db_[0-3].my_table_[0-9]` |
| `--workers` | int | N | worker 数量，默认 0=CPU 数 |

① 二选一：离线模式必须 `--source`；在线模式必须 `--db-connection`。  
离线模式下若额外提供 `--db-connection`，则用于**列名缓存**；不提供时列名回退为 `col_N`。

---

## 四、分库表范围匹配

使用单一的 `--schema-table-regex` 参数进行灵活的数据库和表匹配：

**语法**（简化的区间 + 通配符匹配）：
- `*` - 匹配任意字母/数字/下划线（至少一个）
- `[a-b]` - 整数闭区间匹配，展开为 `(a|a+1|...|b)`
- 其他字符原样匹配

**匹配格式**：`database.table`

**示例**：
| 模式 | 说明 | 匹配示例 |
|------|------|---------|
| `db_[0-9].*` | db_0 到 db_9 库的所有表 | db_0.users, db_5.orders |
| `db_[0-9].table_[0-99]` | db_0~db_9 库中 table_00~table_99 的表 | db_0.table_00, db_5.table_99 |
| `*.users` | 所有库的 users 表 | mydb.users, test.users |
| `[prod,test].*` | prod 或 test 库的所有表 | prod.users, test.logs |

**多条件匹配**：可指定多个 `--schema-table-regex`，支持 OR 逻辑
```bash
binlogx stat --source file.binlog \
  --schema-table-regex "db_[0-3].*" \
  --schema-table-regex "prod.*"
```

**列名缓存键**：
同一范围组合只查询一次元数据，后续命中缓存，**显著减少数据库往返**。

---

## 五、命令专属参数

### 5.1 export
| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `--type` | enum | Y | 导出介质：`csv`,`sqlite`,`h2`,`hive`,`es` |
| `--output` | string | Y | 输出路径或连接串<br>本地文件类（csv/sqlite/h2）**支持自定义文件名**；仅目录时自动生成默认文件名。 |
| `--batch-size` | int | N | 批处理大小，默认 1000。更大值提高性能但占用更多内存 |
| `--estimate-total` | bool | N | 导出前快速扫描统计总事件数，以显示准确进度百分比，默认 false |
| `--action` | string | N | 要导出的事件类型（INSERT,UPDATE,DELETE），默认全部 |

### 5.2 parse
| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| (无) | - | - | 无额外参数，使用全局参数和交互式操作 |

### 5.3 rollback-sql
| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `--bulk` | bool | N | 合并为批量 SQL，默认 false |

### 5.4 stat
| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `--top` | int | N | 仅展示前 N 条统计结果，默认 0（全部） |

---

## 六、核心机制

### 6.1 列名缓存（Table Meta Cache）
- 键：`schemaRegex + tableRegex + column index`
- 生命周期：进程级全局缓存，启动时懒加载，LRU 淘汰（上限 10 000 表）。
- 离线/在线模式只要提供 `--db-connection` 即启用；未提供时透明降级。

### 6.2 生产者-消费者并发模型
- **生产者**：binlog 解析线程（1 条 goroutine）按顺序读取事件 → 解析 → 写入有界 channel（缓冲区 10 000 条）。
- **消费者**：N 条 worker goroutine（默认 `runtime.NumCPU()`）并行处理事件（过滤、转换、写文件/网络）。
- **背压**：channel 满时生产者阻塞，防止内存暴涨。
- **顺序保证**：同一表同一主键的事件路由到固定 worker，确保导出/回滚 SQL 因果有序。
- **可控并发**：通过 `--workers` 调整。

### 6.3 慢方法监控
所有命令入口记录耗时，超过 `--slow-threshold` 打印：方法名、入参、耗时。

### 6.4 大事件预警
单事件字节数 > `--event-size-threshold` 时打印：log-pos、类型、大小。

---

## 七、输出字段统一（parse/sql/export/rollback-sql）
- 时间戳
- 事件类型
- server-id
- log-pos
- 数据库
- 表
- 操作类型
- SQL 语句
- 操作前值（JSON）
- 操作后值（JSON）

---

## 八、Makefile（Go 1.25）
```makefile
build:          # 本地编译
install:        # 安装到 ~/go/bin
cross-compile:  # 生成 5 个平台文件
                # binlogx-linux-amd64
                # binlogx-linux-arm64
                # binlogx-darwin-amd64
                # binlogx-darwin-arm64
                # binlogx-windows-amd64.exe
```

---

## 九、交付物
1. Go 1.25 源码（模块化管理，cobra 命令行，生产者-消费者并发）
2. 单元测试（覆盖核心解析与并发逻辑）
3. README（参数说明、示例、跨平台下载链接）
4. Makefile（build/install/cross-compile）

---

> 用此提示词即可直接开工，或作为 AI 代码生成指令。